{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 500\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "#Importar canasta basica regional deflac\n",
    "CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv')\n",
    "\n",
    "# Load radio ref. Merge regiones.\n",
    "# Anything that is AGLOMERADO 33 should be region Gran Buenos Aires\n",
    "\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv').merge(pd.read_csv('./../data/info/prov_regs.csv'), how = 'left')\n",
    "\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "\n",
    "# DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Resultados estaticos (se toma 1 a√±o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../data/yr_samples\\\\RFReg_0.02ARG2019-03-31.csv',\n",
       " './../data/yr_samples\\\\RFReg_0.02ARG2019-06-30.csv',\n",
       " './../data/yr_samples\\\\RFReg_0.02ARG2019-09-30.csv',\n",
       " './../data/yr_samples\\\\RFReg_0.02ARG2019-12-31.csv']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "# path ='./data/RFReg_' # use your path\n",
    "path ='./../data/yr_samples/RFReg_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "for year in [str(s) for s in range(2019, 2020)]:\n",
    "    allFiles += glob.glob(path +str(frac)+ '*'+str(year)+'*.csv')\n",
    "    # Estos son los archivos que se usan para tener una figura estatica, corte donde no importa evol. temporal.\n",
    "\n",
    "allFiles       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.unique([int(f[-14:-10]) for f in  allFiles])\n",
    "\n",
    "if len(years) == 1:\n",
    "    yr_label = str(years[0])\n",
    "else:\n",
    "    yr_label = '-'.join([str(years.min()), str(years.max())])\n",
    "    \n",
    "yr_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_parts = []\n",
    "for quarter_Xy_file in sorted(allFiles):\n",
    "    df_Q = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO'])\n",
    "    df_Q['ANO4'] = int(quarter_Xy_file[-14:-10])\n",
    "    df_Q['Q'] = quarter_Xy_file[-14:-4]\n",
    "    df_parts += [df_Q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 22.4s\n"
     ]
    }
   ],
   "source": [
    "# use means:\n",
    "df = pd.concat(df_parts)\n",
    "\n",
    "columnas_pesos = ['P47T']\n",
    "df[columnas_pesos] = np.power(10, df[columnas_pesos]) - 1\n",
    "\n",
    "ddf = dd.from_pandas(df, npartitions=50)\n",
    "\n",
    "with ProgressBar():\n",
    "    df = ddf.groupby(['PERSONA_REF_ID','Q']).mean().compute()\n",
    "\n",
    "# Editar columnas\n",
    "df['P10'] = 2 - df['P10']\n",
    "df['P09'] = df.P09.replace(5, 4) #Polimodal tomado como secundario \n",
    "\n",
    "df = df.astype(int)\n",
    "df['P0910'] = df.P09.astype(str) + df.P10.astype(str)\n",
    "df['Grupo Etario'] = pd.cut(df.P03, np.arange(-1, 80, 3))#.round(-1)\n",
    "\n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb = df.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)\n",
    "\n",
    "df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT']].sum()\n",
    "df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT','Pobreza', 'Indigencia']].reset_index()\n",
    "pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "# df = df.sample(25000)\n",
    "data = df.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "data = data.rename(columns = {'P47T': 'P47T_persona'})\n",
    "\n",
    "# data = data\n",
    "data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO']].drop_duplicates())\n",
    "\n",
    "if not os.path.exists('./../data/Pobreza/'):\n",
    "    os.makedirs('./../data/Pobreza/')\n",
    "data.to_csv('./../data/Pobreza/pobreza_'+'_'.join([str(frac), yr_label])+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resultados series de tiempo (se computa para todos y cada trimestre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# path ='./data/RFReg_' # use your path\n",
    "path ='./../data/yr_samples/RFReg_' # use your path\n",
    "\n",
    "allFiles = []\n",
    "for year in [str(s) for s in range(2003, 2021)]:\n",
    "    allFiles += glob.glob(path +str(frac)+ '*'+str(year)+'*.csv')\n",
    "    # Estos son los archivos que se usan para tener una figura estatica, corte donde no importa evol. temporal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-09-30\n",
      "2003-12-31\n",
      "2004-03-31\n",
      "2004-06-30\n",
      "2004-09-30\n",
      "2004-12-31\n",
      "2005-03-31\n",
      "2005-06-30\n",
      "2005-09-30\n",
      "2005-12-31\n",
      "2006-03-31\n",
      "2006-06-30\n",
      "2006-09-30\n",
      "2006-12-31\n",
      "2007-03-31\n",
      "2007-06-30\n",
      "2007-12-31\n",
      "2008-03-31\n",
      "2008-06-30\n",
      "2008-09-30\n",
      "2008-12-31\n",
      "2009-03-31\n",
      "2009-06-30\n",
      "2009-09-30\n",
      "2009-12-31\n",
      "2010-03-31\n",
      "2010-06-30\n",
      "2010-09-30\n",
      "2010-12-31\n",
      "2011-03-31\n",
      "2011-06-30\n",
      "2011-09-30\n",
      "2011-12-31\n",
      "2012-03-31\n",
      "2012-06-30\n",
      "2012-09-30\n",
      "2012-12-31\n",
      "2013-03-31\n",
      "2013-06-30\n",
      "2013-09-30\n",
      "2013-12-31\n",
      "2014-03-31\n",
      "2014-06-30\n",
      "2014-09-30\n",
      "2014-12-31\n",
      "2015-03-31\n",
      "2015-06-30\n",
      "2016-06-30\n",
      "2016-09-30\n",
      "2016-12-31\n",
      "2017-03-31\n",
      "2017-06-30\n",
      "2017-09-30\n",
      "2017-12-31\n",
      "2018-03-31\n",
      "2018-06-30\n",
      "2018-09-30\n",
      "2018-12-31\n",
      "2019-03-31\n",
      "2019-06-30\n",
      "2019-09-30\n",
      "2019-12-31\n",
      "2020-03-31\n",
      "2020-06-30\n"
     ]
    }
   ],
   "source": [
    "for quarter_Xy_file in sorted(allFiles):\n",
    "    df = pd.read_csv(quarter_Xy_file, \n",
    "                           usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'CONDACT', 'CAT_INAC', 'CAT_OCUP',\n",
    "                                      'IX_TOT', 'H16', 'H15','P47T', 'P03','P02', 'P09','P10', 'DPTO'])\n",
    "    df['ANO4'] = int(quarter_Xy_file[-14:-10])\n",
    "    q = quarter_Xy_file[-14:-4]\n",
    "    df['Q'] = q\n",
    "    print(q)\n",
    "    \n",
    "    columnas_pesos = ['P47T']\n",
    "    df[columnas_pesos] = np.power(10, df[columnas_pesos]) - 1\n",
    "\n",
    "#     ddf = dd.from_pandas(df, npartitions=50)\n",
    "#     with ProgressBar():\n",
    "#         df = ddf.groupby(['PERSONA_REF_ID']).mean().compute()\n",
    "\n",
    "    # Editar columnas\n",
    "    df['P10'] = 2 - df['P10']\n",
    "    df['P09'] = df.P09.replace(5, 4) #Polimodal tomado como secundario \n",
    "\n",
    "#     df = df.astype(int)\n",
    "    df['P0910'] = df.P09.astype(str) + df.P10.astype(str)\n",
    "    df['Grupo Etario'] = pd.cut(df.P03, np.arange(-1, 80, 3))#.round(-1)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df_cb = df.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)\n",
    "\n",
    "    df_cb_hogares = df_cb.groupby(['HOGAR_REF_ID', 'Q'])[['P47T','CBA', 'CBT']].sum()\n",
    "    df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "    df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "    pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT','Pobreza', 'Indigencia']].reset_index()\n",
    "    pobreza_hogares['gap_pobreza'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "    pobreza_hogares['gap_indigencia'] = pobreza_hogares.P47T - pobreza_hogares.CBA\n",
    "    pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "    # df = df.sample(25000)\n",
    "    data = df.merge(pobreza_hogares, on = ['HOGAR_REF_ID', 'Q'])#, how = 'left')\n",
    "    data = data.rename(columns = {'P47T': 'P47T_persona'})\n",
    "\n",
    "    # data = data\n",
    "    data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'NOMPROV', 'AGLOMERADO', 'Region']].drop_duplicates())\n",
    "           \n",
    "    if not os.path.exists('./../data/Pobreza/'):\n",
    "        os.makedirs('./../data/Pobreza/')\n",
    "    data.to_csv('./../data/Pobreza/pobreza_'+'_'.join([str(frac), 'q'+q])+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv('./../data/info/ARG_'+str(frac)+'_deflac.csv')\n",
    "\n",
    "# indice_precios = pd.read_csv('./../data/info/indice_pricestats_YQ.csv', index_col=0)\n",
    "# indice_precios.index = pd.DatetimeIndex(indice_precios.index)\n",
    "# indice_precios.index.name = 'Q'\n",
    "\n",
    "# # El indice nos da los valores en pesos para cualquier trimestre. El ultimo es 3er trimestre 2018\n",
    "# inx = indice_precios.tail(1).values[0][0]\n",
    "# df['P47T'] = inx*df['P47T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PERSONA = pd.read_csv('./../extracted_/PERSONA.csv', sep = ';', usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID']) # csv is too big, so it is dask-loaded. Not sure it's efficient thou\n",
    "# PERSONA = PERSONA.loc[PERSONA.PERSONA_REF_ID.isin(df.PERSONA_REF_ID.values)]\n",
    "# df = df.merge(PERSONA, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_ = './data/sample_censo_table_f'+str(frac)+'ARG.csv'\n",
    "\n",
    "# X_censo = pd.read_csv(file_, usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','P03', 'CONDACT', 'AGLOMERADO']).fillna(0)\n",
    "# df = df.drop(['P03', 'CONDACT', 'AGLOMERADO'], axis = 1).merge(X_censo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribucion del ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# fig, ax = plt.subplots(1, figsize = (5, 3))\n",
    "# plt.hist(np.log10(df.loc[df.P47T > 100].P47T).values, 150, normed = 'pdf')#.groupby()\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fig, ax = plt.subplots(1, figsize = (10, 5))\n",
    "# fig, ax = plt.subplots(1, figsize = (5, 3))\n",
    "# df_ = df.groupby('HOGAR_REF_ID').sum()#.loc[df.P47T > 100]\n",
    "# agg = df_.groupby(pd.cut(np.log10(df_.P47T), np.arange(2, 6, .05)))['P47T'].agg(['count','sum'])\n",
    "# (agg/agg.sum()).plot(ax = ax)\n",
    "# # ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular CBA y CBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "# ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "# # Canasta basica 'Alimentaria' y 'Total'\n",
    "# CB = pd.read_csv('./../data/info/canasta.csv')\n",
    "\n",
    "# valor_CB_2018_3 = CB.groupby(['Ano4', 'TRIMESTRE']).mean().loc[2018, 3]\n",
    "\n",
    "# ad_eq['CBA'] = ad_eq['CB_EQUIV']*valor_CB_2018_3.CBA\n",
    "# ad_eq['CBT'] = ad_eq['CB_EQUIV']*valor_CB_2018_3.CBT\n",
    "\n",
    "# ad_eq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mergear en sexo y edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cb = df.merge(ad_eq).sort_values(by = 'HOGAR_REF_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asi, podemos sumar por hogar, y comparar sus costos de canastas con los ingresos estimados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_cb_hogares = df_cb.groupby('HOGAR_REF_ID')[['P47T','CBA', 'CBT']].sum()\n",
    "# df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "# df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # df_cb_hogares.reset_index()['Indigencia'].value_counts()\n",
    "# df_cb_hogares.reset_index()['Pobreza'].value_counts()\n",
    "\n",
    "# # # Pobreza en 17% de los hogares\n",
    "# # 21049/(2945 + 119185)\n",
    "# # # Indig. en 2% de los hogares\n",
    "# # 2945/(2945 + 119185)\n",
    "\n",
    "# pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT','Pobreza', 'Indigencia']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobreza_hogares.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el erorr en una muestra de 1% podriaser de:\n",
    "# +-0.22% en pobreza\n",
    "# 0.01 en indigencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100*df_cb_hogares.reset_index()['Pobreza'].sum()/len(df_cb_hogares)\n",
    "# 100*df_cb_hogares.reset_index()['Indigencia'].sum()/len(df_cb_hogares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # hog_pobres = pobreza_hogares.loc[pobreza_hogares.Pobreza]\n",
    "# pobreza_hogares['gap'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "# # hog_pobres['gap'] = hog_pobres.P47T - hog_pobres.CBT\n",
    "# # hog_pobres.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('./../data/info/ARG_'+str(frac)+'_deflac.csv',\n",
    "                 usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID','RADIO_REF_ID', 'P47T', 'P03','P02', 'P09','P10', 'DPTO'])\n",
    "\n",
    "# Editar columnas\n",
    "df['Grupo Etario'] = pd.cut(df.P03, np.arange(0, 80, 2))#.round(-1)\n",
    "df['P10'] = 2 - df['P10']\n",
    "df['P09'] = df.P09.replace(5, 4) #Polimodal tomado como secundario \n",
    "df['P0910'] = df.P09.astype(str) + df.P10.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20*len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar canasta basica reigonal deflac\n",
    "CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv')\n",
    "CB_ipc = CB_ipc.loc[CB_ipc.Q == '2019-12-31']\n",
    "# CB_ipc = pd.read_csv('./../data/info/CB_Reg_defl.csv').groupby('Region').mean().reset_index()\n",
    "# Se toma nivel de ultimo trimestre. Aca no hay trimestres.\n",
    "\n",
    "# Adulto equivalente. Cuanto cuesta la manutencion de las personas segun sexo y edad.\n",
    "ad_eq = pd.read_csv('./../data/info/adulto_eq.csv')\n",
    "\n",
    "# Load radio ref. Merge regiones.\n",
    "# Anything that is AGLOMERADO 33 should be region Gran Buenos Aires\n",
    "\n",
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv').merge(pd.read_csv('./../data/info/prov_regs.csv'), how = 'left')\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')#.merge(aglo_labels)\n",
    "dpto_region = pd.read_csv('./../data/info/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "\n",
    "DPTO_Region = radio_ref[['DPTO', 'Region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CB_ipc.loc[0, ['CBA', 'CBT']] = .3*CB_ipc.loc[0, ['CBA', 'CBT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar columnas de Pobreza, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb = df.merge(ad_eq).merge(DPTO_Region).merge(CB_ipc)\n",
    "\n",
    "df_cb_hogares = df_cb.groupby('HOGAR_REF_ID')[['P47T','CBA', 'CBT']].sum()\n",
    "df_cb_hogares['Pobreza'] = df_cb_hogares['P47T'] < df_cb_hogares['CBT']\n",
    "df_cb_hogares['Indigencia'] = df_cb_hogares['P47T'] < df_cb_hogares['CBA']\n",
    "pobreza_hogares = df_cb_hogares[['P47T','CBA','CBT','Pobreza', 'Indigencia']].reset_index()\n",
    "pobreza_hogares['gap'] = pobreza_hogares.P47T - pobreza_hogares.CBT\n",
    "pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "\n",
    "# df = df.sample(25000)\n",
    "\n",
    "data = df.merge(pobreza_hogares, on = 'HOGAR_REF_ID', how = 'left')   \n",
    "data = data.rename(columns = {'P47T': 'P47T_persona'})\n",
    "\n",
    "data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'AGLOMERADO']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (13, 6))\n",
    "plt.hist(pobreza_hogares['gap'], np.arange(-30000, 200000, 1000), normed = True)\n",
    "ax.axvline(0, c = 'k')\n",
    "plt.xlim(-30000, 200000)\n",
    "# plt.yscale('log')\n",
    "plt.ylabel('PDF')\n",
    "plt.xlabel('Ingreso del hogar por sobre Canasta Basica (AR$ 2018 Q3)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobreza_hogares.P47T_hogar = pobreza_hogares.P47T_hogar.round()\n",
    "# pobreza_hogares.sort_values(by = 'HOGAR_REF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobreza_hogares.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporadas las columnas de pobreza e indigencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.HOGAR_REF_ID\n",
    "# pobreza_hogares.HOGAR_REF_ID.nunique()\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df tiene ingresos de personas\n",
    "# df.CONDACT.value_counts()\n",
    "# df.P47T.nunique()\n",
    "\n",
    "# # pobreza_hogares tiene ingresos de hogares\n",
    "# pobreza_hogares.HOGAR_REF_ID.nunique()\n",
    "# pobreza_hogares.P47T.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = df.rename(columns = {'P47T': 'P47T_persona'})\n",
    "# pobreza_hogares = pobreza_hogares.rename(columns = {'P47T': 'P47T_hogar'})\n",
    "# data = df.merge(pobreza_hogares, on = 'HOGAR_REF_ID')\n",
    "# data['Grupo Etario'] = pd.cut(data.P03, np.arange(0, 80, 3))#.round(-1)\n",
    "\n",
    "# data['P10'] = 2 - data['P10']\n",
    "# data['P09'] = data.P09.replace(5, 4) #Polimodal tomado como secundario \n",
    "# data['P0910'] = data.P09.astype(str) + data.P10.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*data['Pobreza'].sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*data['Indigencia'].sum()/len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "data = data.merge(radio_ref[['RADIO_REF_ID', 'IDFRAC', 'PROV', 'AGLOMERADO']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "dptos_gdf = gpd.read_file('./../../Documents/censo_geo/pxdptodatosok.shp')\n",
    "dptos_gdf['personas'] = pd.to_numeric(dptos_gdf['personas'])\n",
    "\n",
    "data['link'] = data['DPTO'].astype(str).str.zfill(5)\n",
    "\n",
    "data['Pobreza'] = data['Pobreza'].astype(int)\n",
    "pob_dpto = data.groupby('link')[['Pobreza']].mean().reset_index()\n",
    "\n",
    "pob_dpto_gdf = gpd.GeoDataFrame(pob_dpto.merge(dptos_gdf))\n",
    "# data.groupby('DPTO').count().iloc[:, 0].sort_values(ascending = False).head(10)\n",
    "\n",
    "pob_dpto_gdf.loc[pob_dpto_gdf.personas < 3000, 'Pobreza'] = np.nan\n",
    "pob_dpto_gdf = pob_dpto_gdf.fillna(pob_dpto_gdf.Pobreza.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pob_dpto_gdf#.plot(column = 'Pobreza')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (6, 14))\n",
    "gdf.crs = {'init': 'epsg:4326'}\n",
    "gdf.to_crs({'init': 'epsg:3395'}).fillna(0).plot(column = 'Pobreza', ax = ax, vmin = -.1, vmax = .66, cmap = 'RdYlGn_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (6, 14))\n",
    "gdf.fillna(0).to_crs({'init': 'epsg:3395'}).plot(column = 'Pobreza', ax = ax, vmin = -.1, vmax = .66, cmap = 'RdYlGn_r', \n",
    "                                                edgecolor = '.4', lw = .4)\n",
    "plt.axis('off')\n",
    "plt.xlim(-7200000, -6250000)\n",
    "plt.ylim(-5050000, -3850000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (6, 14))\n",
    "gdf.fillna(0).to_crs({'init': 'epsg:3395'}).plot(column = 'Pobreza', ax = ax, vmin = 0, vmax = .66, cmap = 'RdYlGn_r',\n",
    "                                                 edgecolor = '.4', lw = .4)\n",
    "plt.axis('off')\n",
    "plt.xlim(-6570000, -6450000)\n",
    "plt.ylim(-4150000, -4020000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar Fracciones censales (bueno para algunos aglomerados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_ref.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pob_frac = data.loc[data.AGLOMERADO.isin([32, 33, 2])].groupby(['IDFRAC','DPTO'])[['Pobreza']].mean().reset_index()\n",
    "# pob_frac = data.loc[data.AGLOMERADO.isin([32])].groupby(['IDFRAC','DPTO'])[['Pobreza']].mean().reset_index()\n",
    "pob_frac = data.loc[data.PROV.isin([82])].groupby(['IDFRAC','DPTO'])[['Pobreza']].mean().reset_index()\n",
    "# pob_frac = data.loc[data.AGLOMERADO.isin([25])].groupby(['IDFRAC','DPTO'])[['Pobreza']].mean().reset_index()\n",
    "\n",
    "frac_gdf = gpd.read_file('./../../Documents/censo_geo/pxfracdatosok.shp', )\n",
    "pob_gdf = gpd.GeoDataFrame(pob_frac.merge(frac_gdf), crs = {'init': 'epsg:4326'})\n",
    "# frac_gdf['personas'] = pd.to_numeric(frac_gdf['personas'])\n",
    "\n",
    "# Fill na with median. Esp for areas of little pop.\n",
    "# # data.groupby('DPTO').count().iloc[:, 0].sort_values(ascending = False).head(10)\n",
    "# pob_gdf.loc[pob_gdf.personas < 3000, 'Pobreza'] = np.nan\n",
    "# pob_gdf = pob_gdf.fillna(pob_dpto_gdf.Pobreza.median())\n",
    "\n",
    "gdf = pob_gdf#.plot(column = 'Pobreza')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (15, 14))\n",
    "dptos_gdf.loc[dptos_gdf.codpcia.isin(['02', '06'])].to_crs({'init': 'epsg:3395'}).translate(yoff = 220, xoff = 30).plot(color = 'None', edgecolor = '.4', lw = .4, ax = ax, zorder = 10)\n",
    "gdf.fillna(0).to_crs({'init': 'epsg:3395'}).plot(column = 'Pobreza', ax = ax, vmin = -.2, vmax = .5, cmap = 'RdYlGn_r')\n",
    "plt.axis('off')\n",
    "x1, y1, x2, y2 = tuple(gdf.fillna(0).to_crs({'init': 'epsg:3395'}).total_bounds)\n",
    "plt.xlim(x1, x2)\n",
    "plt.ylim(y1, y2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir mapa en nivel frac censal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pob_frac = data.groupby(['IDFRAC','DPTO'])[['Pobreza']].mean().reset_index()\n",
    "\n",
    "# frac_gdf = gpd.read_file('./../../Documents/censo_geo/pxfracdatosok.shp', )\n",
    "pob_gdf = gpd.GeoDataFrame(pob_frac.merge(frac_gdf), crs = {'init': 'epsg:4326'})\n",
    "\n",
    "\n",
    "# frac_gdf['personas'] = pd.to_numeric(frac_gdf['personas'])\n",
    "\n",
    "# Fill na with median. Esp for areas of little pop.\n",
    "# # data.groupby('DPTO').count().iloc[:, 0].sort_values(ascending = False).head(10)\n",
    "# pob_gdf.loc[pob_gdf.personas < 3000, 'Pobreza'] = np.nan\n",
    "# pob_gdf = pob_gdf.fillna(pob_dpto_gdf.Pobreza.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # niveles de actividad por dpto\n",
    "# data.groupby(['DPTO'])['CONDACT'].value_counts().groupby('DPTO').apply(lambda x: x/x.sum())\n",
    "# data.groupby(['DPTO'])['P0910'].value_counts().groupby('DPTO').apply(lambda x: x/x.sum())\n",
    "\n",
    "# data.nunique()\n",
    "\n",
    "# data.P0910.value_counts()\n",
    "\n",
    "aglo_data = data.loc[data.AGLOMERADO.isin([32, 33])]\n",
    "\n",
    "income = aglo_data.groupby(['DPTO', 'IDFRAC'])['gap'].agg(['count', 'mean', 'median']).reset_index()\n",
    "income_gdf = gpd.GeoDataFrame(income.merge(frac_gdf), \n",
    "                           crs = {'init': 'epsg:4326'})\n",
    "\n",
    "\n",
    "\n",
    "gdf = income_gdf#.plot(column = 'Pobreza')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (15, 14))\n",
    "dptos_gdf.loc[dptos_gdf.codpcia.isin(['02', '06'])].to_crs({'init': 'epsg:3395'}).translate(yoff = 220).plot(color = 'None', edgecolor = '.4', lw = .6, ax = ax, zorder = 10)\n",
    "gdf.fillna(0).to_crs({'init': 'epsg:3395'}).plot(column = 'median', ax = ax, vmin = 0, vmax = 35000, cmap = 'RdYlGn')\n",
    "\n",
    "plt.axis('off')\n",
    "x1, y1, x2, y2 = tuple(gdf.fillna(0).to_crs({'init': 'epsg:3395'}).total_bounds)\n",
    "plt.xlim(x1, x2)\n",
    "plt.ylim(y1, y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['V01', 'H05', 'H06', 'H07', 'H08', 'H09', 'H10',\n",
    "       'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP',\n",
    "       'P02', 'P05', 'P07', 'P08', 'P09', 'P10', 'CAT_OCUP',\n",
    "       'CAT_INAC', 'CH07', 'PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59',\n",
    "       'PP07H', 'PP07I', 'PP07J', 'PP07K',\n",
    "       'AGLOMERADO', 'CONDACT', 'Grupo Etario'] # IX_TOT\n",
    "# value_cols = 'P47T' #?\n",
    "\n",
    "vn = pd.read_csv('./../data/info/VARIABLE_NAMES.csv')\n",
    "# vn['Pregunta'] = vn['Pregunta'].str.strip()#.str.replace(\"'\", \"\") Don't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "condicion = 'Pobreza'\n",
    "for cat in cat_cols[-1:]:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "    info = data.groupby([cat, condicion])[['PERSONA_REF_ID', 'HOGAR_REF_ID']].nunique()\n",
    "    info_pct = (100*(info.unstack()/info.unstack().sum()).stack())\n",
    "    sns.barplot(x=cat, y=\"PERSONA_REF_ID\", hue=condicion, data=info_pct.reset_index(), ax = ax1)\n",
    "    xlab = ''\n",
    "    try:\n",
    "        xlab = vn.loc[vn.Censo == cat]['Pregunta'].values[0]\n",
    "    except:\n",
    "        try:\n",
    "            xlab = vn.loc[vn.EPH == cat]['Pregunta'].values[0]\n",
    "        except:\n",
    "            pass\n",
    "    ax1.set(xlabel= xlab, ylabel = 'porcentaje de PERSONAS')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    sns.barplot(x=cat, y=\"PERSONA_REF_ID\", hue=condicion, data=info.reset_index(), ax = ax2)\n",
    "    ax2.set(xlabel= xlab, ylabel = 'porcentaje de HOGARES \\n con alguien')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
