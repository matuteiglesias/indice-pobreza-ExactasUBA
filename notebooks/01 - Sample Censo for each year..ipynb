{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On this notebook we extract Censo 2010 individual data from their files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los numeros de la tabla proyeccion de poblacion discrepan del censo 2010.\n",
    "# Para solucionar, voy a usar los ratios que propone INDEC post 2010, pero sobreescribiendo el valor de 2010 con lo que dice el censo.\n",
    "proy_pop = pd.read_csv('./../data/info/proy_pop200125.csv', encoding = 'utf-8')\n",
    "\n",
    "# poblacion 2010\n",
    "P02 = pd.read_csv('./../data/info/PERSONA-P02.csv', encoding = 'latin-1')\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "radio_ref['DPTO'] = radio_ref['DPTO'].astype(int)\n",
    "P02_geo = P02.merge(radio_ref[['DPTO', 'NOMDPTO','PROV','NOMPROV', 'radio']])\n",
    "pob2010_DPTO = P02_geo.groupby(['PROV','NOMPROV','DPTO','NOMDPTO'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "merged = proy_pop.merge(pob2010_DPTO, left_on='Cï¿½digo', right_on = 'DPTO') \n",
    "# solo se pierde la antartida\n",
    "merged[[str(s) for s in range(2010, 2026)]] = round(merged[[str(s) for s in range(2010, 2026)]].T*merged.TOTAL/merged['2010']).astype(int).T\n",
    "\n",
    "proy_pob = merged.set_index(['PROV','NOMPROV','DPTO','NOMDPTO'])[[str(s) for s in range(2001, 2026)]]\n",
    "\n",
    "#redo linear interpolation of 2001 -> 2010\n",
    "proy_pob[[str(s) for s in range(2002, 2010)]] = np.nan\n",
    "proy_pob = round(proy_pob.interpolate(axis = 1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacen Falta los datasets PERSONA, VIVIENDA, HOGAR. Se extraen de la base de datos del Censo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular columna IX_TOT (n. personas en hogar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 13.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HOGAR_REF_ID</th>\n",
       "      <th>IX_TOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>746811</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5317447</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10234703</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1602541</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8717569</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  HOGAR_REF_ID  IX_TOT\n",
       "0           0        746811    1694\n",
       "1           1       5317447    1628\n",
       "2           2      10234703    1520\n",
       "3           3       1602541    1410\n",
       "4           4       8717569    1373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Commented after it could be saved\n",
    "# Cantidad de personas  en cada hogar. No esta la columna pero la podemos construir..\n",
    "PERSONA = dd.read_csv('./../../ext_CPV2010_basico_radio_pub/PERSONA.csv', sep = ';', usecols = ['HOGAR_REF_ID']) \n",
    "# Los datasets csv del censo fueron extraidos en ext_CPV2010_basico_radio_pub\n",
    "# Pesa algunos Gb, por eso se carga con dask.\n",
    "\n",
    "with ProgressBar():\n",
    "    IX_TOT = PERSONA['HOGAR_REF_ID'].value_counts().reset_index().compute()\n",
    "    IX_TOT.columns = ['HOGAR_REF_ID', 'IX_TOT']\n",
    "    \n",
    "IX_TOT.to_csv('./../data/info/IX_TOT.csv')\n",
    "\n",
    "IX_TOT = pd.read_csv('./../data/info/IX_TOT.csv')\n",
    "IX_TOT.head() # el tamanio de 12.197.647 hogares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radio_ref = pd.read_csv('./../Censo_individual/data/radio_ref.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar y Vivienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16.7s\n"
     ]
    }
   ],
   "source": [
    "frac = 0.02\n",
    "\n",
    "#Esto es para extraer las viviendas, hogares y personas de los partidos (DPTOs) en cuestion.\n",
    "# seleccion_DPTOS y usecols nos sirven para no cargar data innecesaria.\n",
    "VIVIENDA = dd.read_csv('./../../ext_CPV2010_basico_radio_pub/VIVIENDA.csv', sep = ';', usecols = ['VIVIENDA_REF_ID', 'RADIO_REF_ID', 'TIPVV', 'V01'])\n",
    "VIVIENDA = VIVIENDA.merge(radio_ref[['RADIO_REF_ID', 'DPTO']])\n",
    "\n",
    "\n",
    "# VIVIENDA_ = VIVIENDA.loc[VIVIENDA.DPTO.isin(seleccion_DPTOS)]\n",
    "    \n",
    "HOGAR = dd.read_csv('./../../ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID']) # csv is too big, so it is dask-loaded. Not sure it's efficient thou\n",
    "\n",
    "with ProgressBar():\n",
    "    HOGAR_DPTO = HOGAR.merge(VIVIENDA[['VIVIENDA_REF_ID', 'DPTO']]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "startyr = 2015\n",
    "endyr = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "[########################################] | 100% Completed | 33.5s\n",
      "[########################################] | 100% Completed | 15.4s\n",
      "2016\n",
      "[########################################] | 100% Completed | 33.1s\n",
      "[########################################] | 100% Completed | 15.2s\n",
      "2017\n",
      "[########################################] | 100% Completed | 30.4s\n",
      "[########################################] | 100% Completed | 14.5s\n",
      "2018\n",
      "[########################################] | 100% Completed | 30.0s\n",
      "[########################################] | 100% Completed | 14.5s\n",
      "2019\n",
      "[########################################] | 100% Completed | 30.2s\n",
      "[########################################] | 100% Completed | 15.0s\n",
      "2020\n",
      "[########################################] | 100% Completed | 32.6s\n",
      "[########################################] | 100% Completed | 14.7s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# grouped = HOGAR_DPTO.merge(proyeccion[['DPTO', 'ratio_18']]).groupby('DPTO')\n",
    "ratios = proy_pob.div(proy_pob['2010'], 0).reset_index()\n",
    "\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    grouped = HOGAR_DPTO.merge(ratios[['DPTO', yr]]).groupby('DPTO')\n",
    "    sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean()))\n",
    "\n",
    "    HOGAR = dd.read_csv('./../../ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'H05', 'H06', 'H07', 'H08',\n",
    "           'H09', 'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP', 'TOTPERS']) \n",
    "\n",
    "    VIVIENDA_sample = VIVIENDA.loc[VIVIENDA.VIVIENDA_REF_ID.isin(sample.VIVIENDA_REF_ID)]\n",
    "    HOGAR_sample = HOGAR.loc[HOGAR.HOGAR_REF_ID.isin(sample.HOGAR_REF_ID)]\n",
    "\n",
    "    tabla_censo = VIVIENDA_sample.merge(HOGAR_sample)\n",
    "    tabla_censo = tabla_censo.merge(IX_TOT)\n",
    "\n",
    "    with ProgressBar():\n",
    "        table = tabla_censo.compute()\n",
    "\n",
    "\n",
    "    # Approach: modify Census to fit EPH\n",
    "    table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "    table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "    table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "    table['H16'] = table['H16'].clip(0, 9)\n",
    "    table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "    table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "\n",
    "    # saber de que aglo es la persona. Se usa los resultados de cada aglo.\n",
    "    table = table.merge(radio_ref[['RADIO_REF_ID','AGLOMERADO']]) \n",
    "\n",
    "#    Save once to save time in case it fails at this step.\n",
    "    if not os.path.exists('./../data/yr_samples/'):\n",
    "        os.makedirs('./../data/yr_samples/')\n",
    "        \n",
    "    table.to_csv('./../data/yr_samples/sample_censo_table_f'+str(frac)+'_'+yr+'_ARG.csv', index = False)\n",
    "\n",
    "    PERSONA = dd.read_csv('./../../ext_CPV2010_basico_radio_pub/PERSONA.csv', sep = ';', usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID', 'P01', 'P02', 'P03', 'P05', 'P06',\n",
    "           'P07', 'P12', 'P08', 'P09', 'P10', 'CONDACT'])\n",
    "\n",
    "    PERSONA_sample = PERSONA.loc[PERSONA.HOGAR_REF_ID.isin(sample.HOGAR_REF_ID)]\n",
    "\n",
    "\n",
    "    with ProgressBar():\n",
    "        table = table.merge(PERSONA_sample.compute())\n",
    "\n",
    "    table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "\n",
    "    df = table[['RADIO_REF_ID']].merge(radio_ref, on = 'RADIO_REF_ID', how = 'left')\n",
    "#     display(df[['IDPROV','PROV']].nunique())\n",
    "\n",
    "    # Only once to save time in the future\n",
    "    table.to_csv('./../data/yr_samples/sample_censo_table_f'+str(frac)+'_'+yr+'_ARG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
