{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "import glob\n",
    "path ='./../../../Documents/EPH/microdatos/' # use your path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento: Cargar sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, s in enumerate(['hogar']):#, 'individual']):\n",
    "#     allFiles = glob.glob(path + s + '/*.sav')\n",
    "    \n",
    "#     for file_ in allFiles:\n",
    "#         print(file_)\n",
    "# #         pd.read_stata(file_, encoding='latin')\n",
    "#         pd.read_sas(file_, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento: Cargar dbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "import pysal as ps\n",
    "from itertools import compress\n",
    "\n",
    "'''\n",
    "Arguments\n",
    "---------\n",
    "dbfile  : DBF file - Input to be imported\n",
    "upper   : Condition - If true, make column heads upper case\n",
    "'''\n",
    "\n",
    "drop_cols = {'IV1_ESP', 'IV3_ESP', 'IV7_ESP', 'II7_ESP', 'II8_ESP', 'PP09A_ESP', 'PP09C_ESP', 'PJ1_1',\n",
    " 'PJ2_1', 'PJ3_1', 'FILTER__', 'PP04B_COD','PP11B_COD', 'PP04B_CAES', 'PP11B_CAES', 'II7_ESP0', 'II8_ESP0', 'II8_ESPES'}\n",
    "\n",
    "def dbf2DF(dbfile): #Reads in DBF files and returns Pandas DF\n",
    "    db = ps.open(dbfile) #Pysal to open DBF\n",
    "    print(db.header)\n",
    "    print(drop_cols)\n",
    "    db.header = list(compress(db.header, [col not in drop_cols for col in db.header]))\n",
    "    print(db.header)\n",
    "    d = {col: db.by_col(col) for col in db.header}\n",
    "    pandasDF = pd.DataFrame(d) #Convert to Pandas DF\n",
    "\n",
    "    db.close() \n",
    "    return pandasDF\n",
    "\n",
    "# Return the longest prefix of all list elements.\n",
    "def commonprefix(m):\n",
    "    \"Given a list of pathnames, returns the longest common leading component\"\n",
    "    if not m: return ''\n",
    "    s1 = min(m)\n",
    "    s2 = max(m)\n",
    "    for i, c in enumerate(s1):\n",
    "        if c != s2[i]:\n",
    "            return s1[:i]\n",
    "    return s1\n",
    "\n",
    "from simpledbf import Dbf5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def dbf2DF_custom(dbfile): #Reads in DBF files and returns Pandas DF\n",
    "#     db = ps.open(dbfile) #Pysal to open DBF\n",
    "# #     print(db.header)\n",
    "#     d = {col: db.by_col(col) for col in db.header} #Convert dbf to dictionary. \n",
    "# #     d = {col: db.by_col(col) for col in db.header if '_ESP' not in col} #Convert dbf to dictionary. \n",
    "\n",
    "#     pandasDF = pd.DataFrame(d) #Convert to Pandas DF\n",
    "#     db.close() \n",
    "#     return pandasDF\n",
    "\n",
    "# df = dbf2DF_custom('./../../Documents/EPH/microdatos/hogar/hogar_t314.dbf')\n",
    "\n",
    "# V2_t314 = df['V2_ESPES'].to_csv('hogar_V2_t314', index = False)\n",
    "# V2_t314 = pd.read_csv('hogar_V2_t314')\n",
    "# df.insert(45, 'V2', V2_t314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Column name debug\n",
    "# # # c2 = df_list[-1].columns\n",
    "# # # c3 = df_list[-2].columns\n",
    "\n",
    "# c2 = ['CODUSU', 'NRO_HOGAR', 'COMPONENTE', 'H15', 'ANO4', 'TRIMESTRE', 'REGION', 'MAS_500', 'AGLOMERADO', 'PONDERA', 'CH03', 'CH04', 'CH06', 'CH07', 'CH08', 'CH09', 'CH10', 'CH11', 'CH12', 'CH13', 'CH14', 'CH15', 'CH15_COD', 'CH16', 'CH16_COD', 'NIVEL_ED', 'ESTADO', 'CAT_OCUP', 'CAT_INAC', 'PP02C1', 'PP02C2', 'PP02C3', 'PP02C4', 'PP02C5', 'PP02C6', 'PP02C7', 'PP02C8', 'PP02E', 'PP02H', 'PP02I', 'PP03C', 'PP03D', 'PP3E_TOT', 'PP3F_TOT', 'PP03G', 'PP03H', 'PP03I', 'PP03J', 'INTENSI', 'PP04A', 'PP04B1', 'PP04B2', 'PP04B3_MES', 'PP04B3_ANO', 'PP04B3_DIA', 'PP04C', 'PP04C99', 'PP04D_COD', 'PP04G', 'PP05B2_MES', 'PP05B2_ANO', 'PP05B2_DIA', 'PP05C_1', 'PP05C_2', 'PP05C_3', 'PP05E', 'PP05F', 'PP05H', 'PP06A', 'PP06C', 'PP06D', 'PP06E', 'PP06H', 'PP07A', 'PP07C', 'PP07D', 'PP07E', 'PP07F1', 'PP07F2', 'PP07F3', 'PP07F4', 'PP07F5', 'PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K', 'PP08D1', 'PP08D4', 'PP08F1', 'PP08F2', 'PP08J1', 'PP08J2', 'PP08J3', 'PP09A', 'PP09B', 'PP09C', 'PP10A', 'PP10C', 'PP10D', 'PP10E', 'PP11A', 'PP11B1', 'PP11B2_MES', 'PP11B2_ANO', 'PP11B2_DIA', 'PP11C', 'PP11C99', 'PP11D_COD', 'PP11G_ANO', 'PP11G_MES', 'PP11G_DIA', 'PP11L', 'PP11L1', 'PP11M', 'PP11N', 'PP11O', 'PP11P', 'PP11Q', 'PP11R', 'PP11S', 'PP11T', 'P21', 'DECOCUR', 'IDECOCUR', 'RDECOCUR', 'GDECOCUR', 'PDECOCUR', 'ADECOCUR', 'TOT_P12', 'P47T', 'DECINDR', 'IDECINDR', 'RDECINDR', 'GDECINDR', 'PDECINDR', 'ADECINDR', 'V2_M', 'V3_M', 'V4_M', 'V5_M', 'V8_M', 'V9_M', 'V10_M', 'V11_M', 'V12_M', 'V18_M', 'V19_AM', 'V21_M', 'T_VI', 'ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'IPCF', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'IDIMPP']\n",
    "\n",
    "# dict(zip(s2, hogar_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = ['CODUSUAR', 'NRO_HOGAR', 'REALIZADA', 'ANO4STRE', 'TRIMESTRE', 'REGIONDO', 'MAS_500DO', 'AGLOMERADO', 'PONDERA', 'IV1ESP', 'IV1_ESP', 'IV2ESP', 'IV3ESP', 'IV3_ESP', 'IV4ESP', 'IV5ESP', 'IV6ESP', 'IV7ESP', 'IV7_ESP', 'IV81', 'IV91', 'IV101', 'IV111', 'IV12_1', 'IV12_2', 'IV12_3', 'II11P', 'II21P', 'II31P', 'II3_1P', 'II4_1P', 'II4_2P', 'II4_3P0', 'II51P0', 'II5_1P0', 'II61P0', 'II6_1P0', 'II7ESP0', 'II7_ESP0', 'II8ESP0', 'II8_ESP0', 'II9A00', 'V1A00', 'V2A00', 'V21A00', 'V22A00', 'V3A00', 'V4A00', 'V5A00', 'V6A00', 'V7A00', 'V8A00', 'V9A00', 'V10A00', 'V11A00', 'V12A00', 'V13A00', 'V14A00', 'V15A00', 'V16A00', 'V17A00', 'V18A00', 'V19_A00', 'V19_B00', 'IX_TOT00', 'IX_MEN100', 'IX_MAYEQ10', 'ITFFRDO', 'DECIFRDO', 'IDECIFRDO', 'RDECIFRDO', 'GDECIFRDO', 'PDECIFRDO', 'ADECIFRDO', 'IPCFRDO', 'DECCFRDO', 'IDECCFRDO', 'RDECCFRDO', 'GDECCFRDO', 'PDECCFRDO', 'ADECCFRDO', 'VII1_1DO', 'VII1_2DO', 'VII2_1Q10', 'VII2_2Q10', 'VII2_3Q10', 'VII2_4Q10', 'IDIMPHQ10']\n",
    "s2 = ['CODUSUAR', 'NRO_HOGAR', 'REALIZADA', 'ANO4STRE', 'TRIMESTRE', 'REGIONDO', 'MAS_500DO', 'AGLOMERADO', 'PONDERA', 'IV1ESP', 'IV2ESP', 'IV3ESP', 'IV4ESP', 'IV5ESP', 'IV6ESP', 'IV7ESP', 'IV81', 'IV91', 'IV101', 'IV111', 'IV12_1', 'IV12_2', 'IV12_3', 'II11P', 'II21P', 'II31P', 'II3_1P', 'II4_1P', 'II4_2P', 'II4_3P0', 'II51P0', 'II5_1P0', 'II61P0', 'II6_1P0', 'II7ESP0', 'II7_ESP0', 'II8ESP0', 'II8_ESP0', 'II9A00', 'V1A00', 'V2A00', 'V21A00', 'V22A00', 'V3A00', 'V4A00', 'V5A00', 'V6A00', 'V7A00', 'V8A00', 'V9A00', 'V10A00', 'V11A00', 'V12A00', 'V13A00', 'V14A00', 'V15A00', 'V16A00', 'V17A00', 'V18A00', 'V19_A00', 'V19_B00', 'IX_TOT00', 'IX_MEN100', 'IX_MAYEQ10', 'ITFFRDO', 'DECIFRDO', 'IDECIFRDO', 'RDECIFRDO', 'GDECIFRDO', 'PDECIFRDO', 'ADECIFRDO', 'IPCFRDO', 'DECCFRDO', 'IDECCFRDO', 'RDECCFRDO', 'GDECCFRDO', 'PDECCFRDO', 'ADECCFRDO', 'VII1_1DO', 'VII1_2DO', 'VII2_1Q10', 'VII2_2Q10', 'VII2_3Q10', 'VII2_4Q10', 'IDIMPHQ10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IV1_ESP', 'IV3_ESP', 'IV7_ESP', 'II7_ESP0', 'II8_ESP0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil = [col in drop_cols for col in ['CODUSUAR', 'NRO_HOGAR', 'REALIZADA', 'ANO4STRE', 'TRIMESTRE', 'REGIONDO', 'MAS_500DO', 'AGLOMERADO', 'PONDERA', 'IV1ESP', 'IV1_ESP', 'IV2ESP', 'IV3ESP', 'IV3_ESP', 'IV4ESP', 'IV5ESP', 'IV6ESP', 'IV7ESP', 'IV7_ESP', 'IV81', 'IV91', 'IV101', 'IV111', 'IV12_1', 'IV12_2', 'IV12_3', 'II11P', 'II21P', 'II31P', 'II3_1P', 'II4_1P', 'II4_2P', 'II4_3P0', 'II51P0', 'II5_1P0', 'II61P0', 'II6_1P0', 'II7ESP0', 'II7_ESP0', 'II8ESP0', 'II8_ESP0', 'II9A00', 'V1A00', 'V2A00', 'V21A00', 'V22A00', 'V3A00', 'V4A00', 'V5A00', 'V6A00', 'V7A00', 'V8A00', 'V9A00', 'V10A00', 'V11A00', 'V12A00', 'V13A00', 'V14A00', 'V15A00', 'V16A00', 'V17A00', 'V18A00', 'V19_A00', 'V19_B00', 'IX_TOT00', 'IX_MEN100', 'IX_MAYEQ10', 'ITFFRDO', 'DECIFRDO', 'IDECIFRDO', 'RDECIFRDO', 'GDECIFRDO', 'PDECIFRDO', 'ADECIFRDO', 'IPCFRDO', 'DECCFRDO', 'IDECCFRDO', 'RDECCFRDO', 'GDECCFRDO', 'PDECCFRDO', 'ADECCFRDO', 'VII1_1DO', 'VII1_2DO', 'VII2_1Q10', 'VII2_2Q10', 'VII2_3Q10', 'VII2_4Q10', 'IDIMPHQ10']]\n",
    "\n",
    "list(compress(['CODUSUAR', 'NRO_HOGAR', 'REALIZADA', 'ANO4STRE', 'TRIMESTRE', 'REGIONDO', 'MAS_500DO', 'AGLOMERADO', 'PONDERA', 'IV1ESP', 'IV1_ESP', 'IV2ESP', 'IV3ESP', 'IV3_ESP', 'IV4ESP', 'IV5ESP', 'IV6ESP', 'IV7ESP', 'IV7_ESP', 'IV81', 'IV91', 'IV101', 'IV111', 'IV12_1', 'IV12_2', 'IV12_3', 'II11P', 'II21P', 'II31P', 'II3_1P', 'II4_1P', 'II4_2P', 'II4_3P0', 'II51P0', 'II5_1P0', 'II61P0', 'II6_1P0', 'II7ESP0', 'II7_ESP0', 'II8ESP0', 'II8_ESP0', 'II9A00', 'V1A00', 'V2A00', 'V21A00', 'V22A00', 'V3A00', 'V4A00', 'V5A00', 'V6A00', 'V7A00', 'V8A00', 'V9A00', 'V10A00', 'V11A00', 'V12A00', 'V13A00', 'V14A00', 'V15A00', 'V16A00', 'V17A00', 'V18A00', 'V19_A00', 'V19_B00', 'IX_TOT00', 'IX_MEN100', 'IX_MAYEQ10', 'ITFFRDO', 'DECIFRDO', 'IDECIFRDO', 'RDECIFRDO', 'GDECIFRDO', 'PDECIFRDO', 'ADECIFRDO', 'IPCFRDO', 'DECCFRDO', 'IDECCFRDO', 'RDECCFRDO', 'GDECCFRDO', 'PDECCFRDO', 'ADECCFRDO', 'VII1_1DO', 'VII1_2DO', 'VII2_1Q10', 'VII2_2Q10', 'VII2_3Q10', 'VII2_4Q10', 'IDIMPHQ10'], fil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indiv_cols = ['CODUSU', 'NRO_HOGAR', 'COMPONENTE', 'H15', 'ANO4', 'TRIMESTRE', 'REGION', 'MAS_500', 'AGLOMERADO', 'PONDERA', 'CH03', 'CH04', 'CH06', 'CH07', 'CH08', 'CH09', 'CH10', 'CH11', 'CH12', 'CH13', 'CH14', 'CH15', 'CH15_COD', 'CH16', 'CH16_COD', 'NIVEL_ED', 'ESTADO', 'CAT_OCUP', 'CAT_INAC', 'PP02C1', 'PP02C2', 'PP02C3', 'PP02C4', 'PP02C5', 'PP02C6', 'PP02C7', 'PP02C8', 'PP02E', 'PP02H', 'PP02I', 'PP03C', 'PP03D', 'PP3E_TOT', 'PP3F_TOT', 'PP03G', 'PP03H', 'PP03I', 'PP03J', 'INTENSI', 'PP04A', 'PP04B1', 'PP04B2', 'PP04B3_MES', 'PP04B3_ANO', 'PP04B3_DIA', 'PP04C', 'PP04C99', 'PP04D_COD', 'PP04G', 'PP05B2_MES', 'PP05B2_ANO', 'PP05B2_DIA', 'PP05C_1', 'PP05C_2', 'PP05C_3', 'PP05E', 'PP05F', 'PP05H', 'PP06A', 'PP06C', 'PP06D', 'PP06E', 'PP06H', 'PP07A', 'PP07C', 'PP07D', 'PP07E', 'PP07F1', 'PP07F2', 'PP07F3', 'PP07F4', 'PP07F5', 'PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K', 'PP08D1', 'PP08D4', 'PP08F1', 'PP08F2', 'PP08J1', 'PP08J2', 'PP08J3', 'PP09A', 'PP09B', 'PP09C', 'PP10A', 'PP10C', 'PP10D', 'PP10E', 'PP11A', 'PP11B1', 'PP11B2_MES', 'PP11B2_ANO', 'PP11B2_DIA', 'PP11C', 'PP11C99', 'PP11D_COD', 'PP11G_ANO', 'PP11G_MES', 'PP11G_DIA', 'PP11L', 'PP11L1', 'PP11M', 'PP11N', 'PP11O', 'PP11P', 'PP11Q', 'PP11R', 'PP11S', 'PP11T', 'P21', 'DECOCUR', 'IDECOCUR', 'RDECOCUR', 'GDECOCUR', 'PDECOCUR', 'ADECOCUR', 'TOT_P12', 'P47T', 'DECINDR', 'IDECINDR', 'RDECINDR', 'GDECINDR', 'PDECINDR', 'ADECINDR', 'V2_M', 'V3_M', 'V4_M', 'V5_M', 'V8_M', 'V9_M', 'V10_M', 'V11_M', 'V12_M', 'V18_M', 'V19_AM', 'V21_M', 'T_VI', 'ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'IPCFR', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'IDIMPP']\n",
    "hogar_cols = ['CODUSU', 'NRO_HOGAR', 'REALIZADA', 'ANO4', 'TRIMESTRE', 'REGION', 'MAS_500', 'AGLOMERADO', 'PONDERA', 'IV1', 'IV2', 'IV3', 'IV4', 'IV5', 'IV6', 'IV7', 'IV8', 'IV9', 'IV10', 'IV11', 'IV12_1', 'IV12_2', 'IV12_3', 'II1', 'II2', 'II3', 'II3_1', 'II4_1', 'II4_2', 'II4_3', 'II5', 'II5_1', 'II61', 'II6_1', 'II7', 'II8', 'II9', 'V1', 'V2', 'V21', 'V22', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18A', 'V19_A', 'V19_B', 'IX_TOT', 'IX_MEN10', 'IX_MAYEQ10', 'ITFFR', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'IPCFR', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'VII1_1', 'VII1_2', 'VII2_1', 'VII2_2', 'VII2_3', 'VII2_4', 'IDIMPH10']\n",
    "\n",
    "\n",
    "# individual\n",
    "used_cols_indiv = ['CODUSU','ANO4','TRIMESTRE','CH04','CH06', 'AGLOMERADO', 'CH09','CH10','CH12','CH13','CH15'] +\\\n",
    "                     ['CH07','ESTADO','CAT_INAC','CAT_OCUP','PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K',\n",
    "                     'P47T', 'V3_M', 'T_VI', 'V12_M', 'TOT_P12', 'V5_M','V2_M', 'PP08D1', 'P21']\n",
    "\n",
    "# hogar\n",
    "used_cols_hogar = ['CODUSU','ANO4','TRIMESTRE','IX_TOT', 'AGLOMERADO',\n",
    "    'IV1', 'IV3', 'IV4','IV5','IV6','IV7','IV8','IV10','IV11','II1','II2','II7','II8','II9']\n",
    "\n",
    "# for yr in ['03', '04', '05', '06']:\n",
    "for yr in ['07', '08','09', '10', '11', '12','13', '14', '15']:\n",
    "    for i, s in enumerate(['hogar', 'individual']):\n",
    "        allFiles = glob.glob(path + s + '/*'+yr+'.dbf')\n",
    "        cols = [hogar_cols, indiv_cols][i]\n",
    "        usecols = [used_cols_hogar, used_cols_indiv][i]\n",
    "        for file_ in allFiles:\n",
    "            print(file_)\n",
    "            df = dbf2DF(file_)\n",
    "            df = pd.DataFrame(df.values, columns = cols)\n",
    "            df = df[usecols]\n",
    "            df.to_csv('./../../../Documents/EPH/microdatos/'+file_.split('/')[-2]+'/usu_'+file_.split('/')[-1].replace('.dbf', '.txt'), \n",
    "                      index = False, sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ce3af7760f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial scan for having the column names\n",
    "\n",
    "for i, s in enumerate(['hogar']):#, 'individual']):\n",
    "    allFiles = glob.glob(path + s + '/*.dbf')\n",
    "    allFiles = [f for f in allFiles if 't314' not in f]\n",
    "    allFiles = [f for f in allFiles if 't414' not in f]\n",
    "    allFiles = [f for f in allFiles if 't115' not in f]\n",
    "    allFiles = [f for f in allFiles if 't215' not in f] # Saco estos porque dan problema con la estructura de datos..\n",
    "    corregir = pd.read_csv('./data/EPH2015_colnames_key', index_col=0, header = None).to_dict()[1]\n",
    "    \n",
    "    \n",
    "    colnames = []\n",
    "\n",
    "    df_list = []\n",
    "    for file_ in allFiles:\n",
    "        print(file_)\n",
    "        df = dbf2DF(file_)\n",
    "        colnames += [df.columns.values]\n",
    "        print(len(df.columns))\n",
    "        df_list += [df]\n",
    "\n",
    "    df = pd.DataFrame(colnames)\n",
    "\n",
    "#     cols = []\n",
    "#     for col in df:\n",
    "#         colname = commonprefix(list(df[col].values))\n",
    "#         cols += [colname]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['CODUSUAR', 'NRO_HOGAR', 'REALIZADA', 'ANO4STRE', 'TRIMESTRE', 'REGION', 'MAS_500DO', 'AGLOMERADO', 'PONDERA', 'IV1ESP', 'IV1_ESP', 'IV2', 'IV3ESP', 'IV3_ESP', 'IV4', 'IV5', 'IV6', 'IV7ESP', 'IV7_ESP', 'IV8', 'IV9', 'IV10', 'IV111', 'IV12_1', 'IV12_2', 'IV12_3', 'II1', 'II2', 'II31', 'II3_1', 'II4_1', 'II4_2', 'II4_3', 'II51', 'II5_1', 'II61', 'II6_1', 'II7ESP', 'II7_ESP', 'II8ESP', 'II8_ESP', 'II9', 'V1', 'V2', 'V21', 'V22', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18A', 'V19_A', 'V19_B', 'IX_TOT0', 'IX_MEN100', 'IX_MAYEQ10', 'ITFFR', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'IPCFR', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'VII1_1', 'VII1_2', 'VII2_1', 'VII2_2', 'VII2_3', 'VII2_4', 'IDIMPH10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = [s[-6:-4]+s[-8:-6] for s in allFiles]\n",
    "# df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, column names are \n",
    "colnames_hogar = pd.read_csv('./../../Documents/EPH/microdatos/colnames_hogar_78', header = None)[0].values\n",
    "colnames_indiv = pd.read_csv('./../../Documents/EPH/microdatos/colnames_indiv_169', header = None)[0].values\n",
    "\n",
    "for i, s in enumerate(['hogar']):#, 'individual']):\n",
    "    colnames = [colnames_hogar, colnames_indiv][i]\n",
    "    used_cols = [used_cols_hogar, used_cols_indiv][i]\n",
    "    allFiles = glob.glob(path + s + '/*.dbf')\n",
    "    allFiles = [f for f in allFiles if 't314' not in f]\n",
    "    allFiles = [f for f in allFiles if 't414' not in f]\n",
    "    allFiles = [f for f in allFiles if 't115' not in f]\n",
    "    allFiles = [f for f in allFiles if 't215' not in f] # Saco estos porque dan problema con la estructura de datos..\n",
    "\n",
    "    df_list = []\n",
    "    for file_ in allFiles[:2]:\n",
    "        print(file_)\n",
    "        df = dbf2DF(file_)\n",
    "        df.columns = colnames\n",
    "        df = df[used_cols]\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        filename = allFiles[i].replace('Hogar', 'usu_hogar'\n",
    "                                      ).replace('Individual', 'usu_individual'\n",
    "                                               ).replace('.dbf', '.txt')\n",
    "        print(filename)\n",
    "        df.to_csv(filename, index = False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_hogar = pd.read_csv('./../../Documents/EPH/microdatos/colnames_hogar_78', header = None)[0].values\n",
    "colnames_hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cols = pd.read_csv('./../../Documents/EPH/microdatos/hogar/usu_hogar_t114.txt', nrows=1, sep = ';').columns\n",
    "len([col for col in ref_cols if 'ESP' not in col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cols = pd.read_csv('./../../Documents/EPH/microdatos/individual/usu_individual_t114.txt', nrows=1, sep = ';').columns\n",
    "len([col for col in ref_cols if 'ESP' not in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = './../../Documents/EPH/microdatos/hogar/hogar_t412.dbf'\n",
    "\n",
    "dbfile = f\n",
    "upper=True\n",
    "db = ps.open(dbfile) #Pysal to open DBF\n",
    "d = {col: db.by_col(col) for col in db.header} #Convert dbf to dictionary\n",
    "#pandasDF = pd.DataFrame(db[:]) #Convert to Pandas DF\n",
    "pandasDF = pd.DataFrame(d) #Convert to Pandas DF\n",
    "if upper == True: #Make columns uppercase if wanted \n",
    "    pandasDF.columns = map(str.upper, db.header) \n",
    "db.close() \n",
    "pandasDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in db.header:\n",
    "    try:\n",
    "        x = db.by_col(col)\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.by_col('CODUSUAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
