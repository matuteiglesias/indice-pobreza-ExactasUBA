{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "def save_geojson(gdf, filename = 'test.geojson'):\n",
    "    try:    # Delete if geojson exists, cause overwriting is not supported\n",
    "        os.remove('./geojson/'+filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    gdf.to_file('./geojson/'+filename, driver=\"GeoJSON\", encoding='utf-8')\n",
    "    \n",
    "from mapbox import Uploader\n",
    "import json\n",
    "\n",
    "def upload_file(data, name, username = 'matuteiglesias', token = 'sk.eyJ1IjoibWF0dXRlaWdsZXNpYXMiLCJhIjoiY2puODA4bW8xMGV1dzNrcGtiOGp6NXQ5aCJ9.DohKmjn_o6MK1Y4Q5FG8ew'):\n",
    "    try:    # Clear upload file if exists\n",
    "        os.remove('./upload_data.geojson')\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    # Dump into file for upload    \n",
    "    with open('./upload_data.geojson', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "    service = Uploader(access_token=token)\n",
    "    with open('./upload_data.geojson', 'rb') as src:\n",
    "        # Acquisition of credentials, staging of data, and upload\n",
    "        # finalization is done by a single method in the Python SDK.\n",
    "        upload_resp = service.upload(src, username+'.'+name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "data_17 = pd.read_csv('./data/pobreza0.04_2017.csv', usecols = ['RADIO_REF_ID', 'HOGAR_REF_ID', 'IX_TOT',\n",
    "       'P03', 'P47T_persona', 'P47T_hogar', 'Pobreza', 'Indigencia'])\n",
    "data_18 = pd.read_csv('./data/pobreza0.04_2018.csv', usecols = ['RADIO_REF_ID', 'HOGAR_REF_ID', 'IX_TOT',\n",
    "       'P03', 'P47T_persona', 'P47T_hogar', 'Pobreza', 'Indigencia'])\n",
    "data = pd.concat([data_17, data_18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "aglo_labels = pd.read_csv('./data/aglo_labels.csv')[['AGLOMERADO', 'NOMAGLO']]\n",
    "radio_ref = pd.read_csv('./data/radio_ref.csv')\n",
    "# radio_ref[['PROV','NOMPROV','DPTO', 'NOMDPTO']].drop_duplicates().to_csv('./data/DPTO_PROV.csv', index = False)\n",
    "dpto_region = pd.read_csv('./data/DPTO_PROV_Region.csv')\n",
    "radio_ref = radio_ref.merge(dpto_region)\n",
    "radio_ref = radio_ref.merge(aglo_labels)\n",
    "radio_ref = radio_ref[['RADIO_REF_ID', 'radio', 'DPTO', 'NOMDPTO', 'AGLOMERADO', 'NOMAGLO', 'PROV', 'NOMPROV', 'Region']].drop_duplicates()\n",
    "radio_ref['radio'] = radio_ref.radio.astype(int).astype(str).str.zfill(9)\n",
    "\n",
    "# radio_ref.to_csv('./data/radio_dpto_aglo_prov.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# df = data.sample(frac = .1/3)\n",
    "# df[['P47T_persona', 'P47T_hogar', 'CBA', 'CBT', 'gap_pobreza', 'gap_indigencia']] = df[['P47T_persona', 'P47T_hogar', 'CBA', 'CBT', 'gap_pobreza', 'gap_indigencia']].round().astype(int)\n",
    "\n",
    "# df = df.sort_values(by = ['HOGAR_REF_ID', 'PERSONA_REF_ID'])\n",
    "# df['Grupo Etario'] = pd.qcut(df.P03, 10)\n",
    "# df.to_csv('./../censo_eph_0.004_20171_20181_20191.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target = data.loc[data.targetencia]\n",
    "target = data.loc[data.Indigencia]\n",
    "# target = data.loc[data.Pobreza]\n",
    "radio_target = target.groupby('RADIO_REF_ID')['HOGAR_REF_ID'].count()\n",
    "radio_target = radio_target.sort_values(ascending = False)\n",
    "radio_target = radio_target.cumsum()/radio_target.sum()\n",
    "radio_target = radio_target.loc[radio_target < .9].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mayores = data.loc[data.P03 >= 24]\n",
    "target = mayores.sort_values('P47T_persona', ascending = False)\n",
    "target = target[:round(.05*len(target))]\n",
    "\n",
    "radio_target = target.groupby('RADIO_REF_ID')['HOGAR_REF_ID'].count()\n",
    "radio_target = radio_target.sort_values(ascending = False)\n",
    "radio_target = radio_target.cumsum()/radio_target.sum()\n",
    "radio_target = radio_target.loc[radio_target < .90].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = radio_target.sort_values(ascending = False).reset_index().merge(radio_ref[['RADIO_REF_ID', 'NOMDPTO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radios_gdf = gpd.GeoDataFrame.from_file('./../../Documents/mapas_censo/poligonos/radios_censales/radios_w_geometry.shp').rename(columns = {'LINK': 'radio'})\n",
    "radios_gdf['link'] = radios_gdf['radio'].str[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(radio_target.merge(\n",
    "    radio_ref[['RADIO_REF_ID', 'radio']]).merge(radios_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gdf = gdf.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radios_indigencia_\n"
     ]
    }
   ],
   "source": [
    "name = 'sample_1000_'\n",
    "\n",
    "save_geojson(gdf, name + '.geojson')\n",
    "\n",
    "username = 'matuteiglesias'\n",
    "token = 'sk.eyJ1IjoibWF0dXRlaWdsZXNpYXMiLCJhIjoiY2puODA4bW8xMGV1dzNrcGtiOGp6NXQ5aCJ9.DohKmjn_o6MK1Y4Q5FG8ew'\n",
    "\n",
    "files = os.listdir('./geojson/')\n",
    "files = [f for f in files if name in f]\n",
    "\n",
    "names = [name.split('.')[0] for name in files]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    print(names[i])\n",
    "    data_ = json.load(open('./geojson/'+files[i]))\n",
    "\n",
    "    try:\n",
    "        upload_file(data_, names[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
